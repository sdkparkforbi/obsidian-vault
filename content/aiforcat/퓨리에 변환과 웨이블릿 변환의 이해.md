## 1️⃣ 서론: 왜 이런 변환이 필요한가

- 우리가 관찰하는 시계열 데이터(소리, 주가, 심전도 등)는 단순히 "시간에 따른 값"이 아님.
- 그 속에는 **여러 주파수 성분**이 섞여 있으며, 이들을 분리해보는 것이 핵심임.
- 마치 음악의 악보를 분석하는 것처럼, **데이터 안의 리듬과 반복**을 이해하는 과정임.

> 💡 **비유:**  
> 시계열을 "노래"라고 생각해보자.  
> 퓨리에 변환은 **노래 전체를 스펙트럼으로 분석**하는 것이고,  
> 웨이블릿 변환은 **시간이 흐르면서 어떤 악기가 언제 등장하는지를 추적**하는 것임.

## 2️⃣ 퓨리에 변환: "전체를 주파수로 본다"

### (1) 기본 개념

- 퓨리에 변환은 함수를 여러 개의 사인/코사인파로 분해하는 도구임.
- 모든 파동은 크기(amplitude)와 위상(phase)을 가진 사인파들의 합으로 표현 가능함.
- 한 주파수에 대응되는 성분이 **데이터 전체에 걸쳐 동일하게 존재한다고 가정**함.

### (2) 수식적 표현

$$ F(\omega) = \int_{-\infty}^{\infty} f(t)e^{-i\omega t}dt $$

- $f(t)$: 시간 영역의 신호
- $F(\omega)$: 주파수 영역의 스펙트럼
- $\omega$: 각주파수(rad/s)

복소수 표현은 다음과 같음.

$$ e^{-i\omega t} = \cos(\omega t) - i\sin(\omega t) $$

이 식은 **회전하는 파동**을 나타냄.

---

### (3) 직관적 이해

- 퓨리에 변환은 **시간 정보를 잃는 대신**,  
    **"이 신호 안에는 어떤 주파수 성분이 들어있는가?"**만을 보여줌.
- 즉, 시간은 무시되고 주파수의 비중만 남음.

> 🎧 **예시:**
> 
> - 음성 전체를 분석하면 "이 사람의 목소리는 300Hz 근처의 성분이 강하다"라고 알 수 있지만,  
>     "언제 높아졌는지"는 모름.

---

## 3️⃣ 퓨리에의 한계: 시간 정보의 상실

- 실제 신호는 **시간에 따라 변화**함.
- 어떤 시점에는 낮은 주파수가, 다른 시점에는 높은 주파수가 등장할 수 있음.
- 하지만 퓨리에 변환은 **"언제"** 그런 주파수가 나타나는지를 알려주지 못함.

> 🎹 **예시:**  
> 피아노 연주를 퓨리에 변환하면,  
> 어떤 음들이 사용되었는지는 알지만 **언제 눌렸는지**는 모름.

---

## 4️⃣ 단기 퓨리에 변환(STFT): 한계 완화의 시도

### (1) 아이디어

- "시간 창(window)"을 만들어, 짧은 구간만 변환
- 구간을 조금씩 옮기면서 전체 시간에 대한 주파수 변화를 추적

### (2) 단점

- **창 크기(window size)의 딜레마:**
    - 창이 넓으면 → 주파수 해상도는 높지만, 시간 변화는 흐릿
    - 창이 좁으면 → 시간 해상도는 높지만, 주파수 구분이 불분명

> 💬 **즉:** 시간과 주파수의 해상도는 서로 반비례 관계임.  
> 이것이 **나이키스트(Nyquist)**와 **하이젠베르크 불확정성 원리**가 연결되는 지점임.

---

## 5️⃣ 웨이블릿 변환: "시간과 주파수를 함께 본다"

### (1) 기본 개념

- 웨이블릿(Wavelet)은 **길이가 유한한 작은 파동("wave-let")**임.
- 모함수(Mother Wavelet)를 늘이거나 줄여서,  
    다양한 주파수대역을 시간축 위에서 탐색함.
- 즉, **짧은 파동을 이용해 신호를 스캔**하는 방식임.

$$ W(a, b) = \int_{-\infty}^{\infty} f(t)\psi^{*}\left(\frac{t-b}{a}\right)dt $$

- $a$: 스케일(scale, 주파수의 역수 역할)
- $b$: 시간 이동(time shift)
- $\psi(t)$: 모함수(mother wavelet)


  실수 웨이블릿: Mexican Hat
$$ ψ(t) = (1 - t²) · exp(-t²/2) $$ 

  복소수 웨이블릿: Morlet
$$ ψ(t) = exp(iω₀t) · exp(-t²/2) $$

### (2) 직관적으로 보면

- 작은 스케일 → 높은 주파수, 세밀한 시간 정보
- 큰 스케일 → 낮은 주파수, 느린 변화 포착

> 🧩 **비유:**  
> 확대경을 바꿔가며 지도를 보는 것과 같음.  
> 큰 확대경으로는 전체 지형(저주파)을,  
> 작은 확대경으로는 세부 지형(고주파)을 봄.

---

## 6️⃣ 퓨리에 vs 웨이블릿 비교 요약

| 구분      | 퓨리에 변환            | 웨이블릿 변환                                            |
| ------- | ----------------- | -------------------------------------------------- |
| 분석 단위   | 무한 길이의 사인파        | 짧은 길이의 웨이블릿                                        |
| 시간 정보   | 없음                | 있음                                                 |
| 주파수 해상도 | 일정함               | 스케일에 따라 가변적                                        |
| 적용 사례   | 음성 전체 스펙트럼, 필터 설계 | 지진파, EEG(Electroencephalography, 뇌전도/뇌파), 주가 급변 탐지 |
| 대표 결과   | 스펙트럼(주파수-진폭)      | 시간-주파수 스펙트럼                                        |
|         |                   |                                                    |

---

## 7️⃣ 예시: 시간에 따라 변하는 주파수 시뮬레이션

https://colab.research.google.com/drive/1XpBSKXZYDWwQiC0eHpe329YCVfhDcWuT?usp=sharing

```python
!pip install -q koreanize_matplotlib
import koreanize_matplotlib

import numpy as np
import matplotlib.pyplot as plt
import pywt
import koreanize_matplotlib

# 신호 생성
t = np.linspace(0, 5, 1000)
signal = np.concatenate([
    np.sin(2 * np.pi * 5 * t[:300]),     # 5Hz
    np.sin(2 * np.pi * 15 * t[300:600]), # 15Hz
    np.sin(2 * np.pi * 30 * t[600:])     # 30Hz
])

# 웨이블릿 변환
scales = np.arange(1, 128)
coeffs, freqs = pywt.cwt(signal, scales, 'cmor1.5-1.0', sampling_period=1/200)

# 스케일로 그리기
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

# 원본 신호
ax1.plot(t, signal)
ax1.set_title("원본 신호")
ax1.set_xlabel("시간 (초)")
ax1.set_ylabel("진폭")
ax1.axvline(1.5, color='r', linestyle='--', alpha=0.5, label='5Hz→15Hz')
ax1.axvline(3, color='r', linestyle='--', alpha=0.5, label='15Hz→30Hz')
ax1.grid(True, alpha=0.3)

# 스케일 기준 스펙트럼
im = ax2.imshow(np.abs(coeffs), 
                extent=[0, 5, scales[-1], scales[0]], 
                cmap='hot', 
                aspect='auto')
ax2.set_title("웨이블릿 스펙트럼 (Y축 = 스케일)")
ax2.set_xlabel("시간 (초)")
ax2.set_ylabel("스케일 (a)")
ax2.invert_yaxis()  # 작은 스케일이 위로

# 주요 스케일 표시
important_scales = [7, 13, 40]  # 대략 30Hz, 15Hz, 5Hz
for s in important_scales:
    ax2.axhline(s, color='white', linestyle=':', alpha=0.7, linewidth=0.8)
    ax2.text(4.5, s, f'a={s}', color='yellow', fontsize=10)

plt.colorbar(im, ax=ax2, label='계수 크기')
plt.tight_layout()
plt.show()

# 스케일과 주파수의 관계 분석
print("="*60)
print("스케일(a)과 주파수의 관계")
print("="*60)
print("공식: 주파수 = (중심주파수 × 샘플링주파수) / 스케일")
print("      주파수 = (1.0 × 200) / a = 200/a")
print("-"*60)

# 주요 스케일과 주파수
key_scales = [1, 5, 7, 10, 13, 20, 40, 60, 100, 127]
print(f"{'스케일(a)':>10} | {'주파수(Hz)':>12} | {'특징':>20}")
print("-"*60)

for s in key_scales:
    idx = s - 1
    f = freqs[idx]
    if s == 7:
        note = "≈ 30Hz 신호"
    elif s == 13:
        note = "≈ 15Hz 신호"
    elif s == 40:
        note = "≈ 5Hz 신호"
    else:
        note = ""
    print(f"{s:10d} | {f:12.2f} | {note:>20}")

# 시각적 관계 표시
plt.figure(figsize=(12, 5))

plt.subplot(121)
plt.plot(scales, freqs, 'b-', linewidth=2)
plt.xlabel("스케일 (a)")
plt.ylabel("주파수 (Hz)")
plt.title("스케일-주파수 관계 (반비례)")
plt.grid(True, alpha=0.3)

# 주요 포인트 표시
for s, target_f in [(40, 5), (13, 15), (7, 30)]:
    idx = s - 1
    plt.plot(s, freqs[idx], 'ro', markersize=10)
    plt.annotate(f'{target_f}Hz\n(a={s})', 
                xy=(s, freqs[idx]), 
                xytext=(s+5, freqs[idx]+10),
                arrowprops=dict(arrowstyle='->', color='red'),
                fontsize=10)

plt.subplot(122)
plt.semilogy(scales, freqs, 'g-', linewidth=2)
plt.xlabel("스케일 (a)")
plt.ylabel("주파수 (Hz) - 로그 스케일")
plt.title("스케일-주파수 관계 (로그 스케일)")
plt.grid(True, alpha=0.3)

# 주요 포인트 표시
for s, target_f in [(40, 5), (13, 15), (7, 30)]:
    idx = s - 1
    plt.plot(s, freqs[idx], 'ro', markersize=10)

plt.tight_layout()
plt.show()

# 주파수 기준으로 재정렬
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# 1. 원본 (스케일 순서)
im1 = axes[0].imshow(np.abs(coeffs), 
                       extent=[0, 5, scales[-1], scales[0]], 
                       cmap='hot', aspect='auto')
axes[0].set_title("원본: 스케일 순서대로")
axes[0].set_xlabel("시간 (초)")
axes[0].set_ylabel("스케일 인덱스")
axes[0].invert_yaxis()
 
# 2. 보간을 통한 균일 주파수 그리드
# 균일한 주파수 그리드 생성
freq_uniform = np.linspace(1, 50, 100)
time_points = np.arange(coeffs.shape[1])

# 각 시간에 대해 보간
from scipy.interpolate import interp1d
coeffs_interp = np.zeros((len(freq_uniform), len(time_points)), dtype=complex)

for t_idx in range(len(time_points)):
    # 주파수가 감소하는 순서로 정렬
    f_interp = interp1d(freqs[::-1], coeffs[::-1, t_idx], 
                       kind='linear', fill_value=0, bounds_error=False)
    coeffs_interp[:, t_idx] = f_interp(freq_uniform)

im4 = axes[1].imshow(np.abs(coeffs_interp), 
                       extent=[0, 5, freq_uniform[0], freq_uniform[-1]], 
                       cmap='hot', aspect='auto',
                       origin='lower')
axes[1].set_title("균일 주파수 그리드로 재샘플링\n(보간 사용)")
axes[1].set_xlabel("시간 (초)")
axes[1].set_ylabel("주파수 (Hz)")

# 주파수 참조선
for f in [5, 15, 30]:
    axes[1].axhline(f, color='cyan', linestyle=':', alpha=0.7)
    axes[1].text(0.1, f, f'{f}Hz', color='cyan', fontsize=9)

# 컬러바 추가
for ax, im in zip(axes.flat, [im1, im2, im3, im4]):
    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

plt.tight_layout()
plt.show()
```

> 🔍 **해석:**
> 
> - 시간 0~2초: 저주파(5Hz)
> - 2~3초: 중간 주파수(15Hz)
> - 3초 이후: 고주파(30Hz)  
>     → 퓨리에 변환은 이 차이를 구분하지 못하지만,  
>     웨이블릿 변환은 시간 축에서 각 주파수의 등장 시점을 보여줌.

---

## 8️⃣ 실제 활용 사례

- **EEG(뇌파) 분석:** 특정 뇌 영역의 순간적 고주파 활성 포착
- **지진파 분석:** P파·S파 등 서로 다른 주파수대 파형 구분
- **금융 시계열:** 급등락 구간에서 단기·장기 주기 분리
- **음성·음악:** 시간-주파수 에너지 분포 추적

---

## 9️⃣ 마무리

> 🧠 퓨리에 변환은 "전체 주파수 구성"을,  
> 🕓 웨이블릿 변환은 "시간에 따라 변하는 주파수"를 보여줌.
> 
> 따라서 데이터가 **비정상(non-stationary)**하다면,  
> 웨이블릿이 더 현실적인 분석 도구임.

---

## 📚 참고문헌 및 확장 자료

- Mallat, S. (2009). _A Wavelet Tour of Signal Processing._ Academic Press.
- Torrence, C., & Compo, G. P. (1998). _A practical guide to wavelet analysis._ Bulletin of the American Meteorological Society.
- Addison, P. S. (2017). _The Illustrated Wavelet Transform Handbook._ CRC Press.